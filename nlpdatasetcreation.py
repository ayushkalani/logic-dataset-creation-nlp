# -*- coding: utf-8 -*-
"""NLPDatasetCreation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mGnhMOsSVj8f3HdGj4te11xqDyfXF1v_
"""

# Wordnet
!pip install names
CONCEPT_NET_URL = 'http://api.conceptnet.io/query'
import nltk
nltk.download('wordnet')
from nltk.corpus import wordnet

"""**UTILITY COMMON FUNCTIONS**"""

import names, requests
# CONSTANTS
PATTERN = r"[\([{})\]]"
OPERATORS = ["and", "or"]
CSV_COLUMNS = ['UUID','Rules','Context','Questions','Answers']
FREQUENT_WORDS = ["animals", "countries", "cities", "sports", "cultures", "dogs", "cats", "buildings", "colleges", "subjects", "lakes", "mountains", "dishes", 'area','book','business','case','child','company','country','day','eye','fact','family','government','group','hand','home','job','life','lot','man','money','month','mother','Mr','night','number','part','people','place','point','problem','program','question','right','room','school','state','story','student','study','system','thing','time','water','way','week','woman','word','work','world','year']
RELATIONS = ['RelatedTo','IsA','FormOf','PartOf','SimilarTo','HasA','UsedFor','CapableOf','AtLocation','Causes','HasSubevent','HasPrerequisite','HasProperty','MotivatedByGoal','ObstructedBy','Desires','CreatedBy','Synonym','DistinctFrom','DerivedFrom','SymbolOf','DefinedAs','MannerOf','LocatedNear','HasContext','EtymologicallyRelatedTo','EtymologicallyDerivedFrom','CausesDesire','MadeOf','ReceivesAction']
YES ="yes"
NO = "no"

# Relations
CONJUNCTION_RELATIONS = ["HasA"]
ADDITION_RELATIONS = ["HasA"]
COMPOSITION_RELATIONS = ["HasPrerequisite", "MannerOf"]
DEMORGAN_1_RELATIONS = ["HasA"]

COMPOSITION_WORDS = ["play", "dream"]

# NOUNS = [word for synset in wordnet.all_synsets('n') for word in synset.lemma_names()

def create_premise(klass, *sentences):
  premise = ""
  for s in sentences:
    premise += (s + ". ")
  name = names.get_first_name()
  inference = "{} is a {}".format(name, klass)
  premise += inference
  return [premise, name]

def question_answer_pairs(questions, ans):
  return {"Questions": questions, "Answers": [ans] * len(questions) }

def get_synonym_of_word(klass):
  url = '{}?end=/c/en/{}&rel=/r/Synonym&limit=1000'.format(CONCEPT_NET_URL, klass)
  obj = requests.get(url).json()
  # return the first antonym
  for edge in obj['edges']:
    return (edge['start']['label'] or '')     

def get_antonym_of_word(klass):
  url = '{}?end=/c/en/{}&rel=/r/Antonym&limit=1000&filter=/c/en'.format(CONCEPT_NET_URL, klass)
  obj = requests.get(url).json()
  # return the first antonym
  for edge in obj['edges']:
    return (edge['start']['label'] or getAntonym(klass))

def getSynonym(word):
  synonyms = []
  for syn in wordnet.synsets(word):
      for lm in syn.lemmas():
              synonyms.append(lm.name())
  for syn in synonyms:
    if word != syn:
      return (syn or '')
  return ''

def getAntonym(word):
  antonyms = []
  for syn in wordnet.synsets(word):
      for lm in syn.lemmas():
          if lm.antonyms():
              antonyms.append(lm.antonyms()[0].name())
  for syn in antonyms:
    if word != syn:
      return (syn or '')
  return ''

def verb_list():
  url = 'https://raw.githubusercontent.com/dariusk/corpora/master/data/words/verbs.json'
  response = requests.get(url).json()
  verb_list = []
  for verb in response['verbs']:
    verb_list.append(verb['present'])
  return verb_list

VERB_LIST = verb_list()
#adding more words
COMPOSITION_WORDS.extend(VERB_LIST)

"""**CONJUNCTION:**

"""

def create_question_type_1(questionable_name, word):
  return "Does {} has {}?".format(questionable_name, word)

def create_question_type_2(questionable_name, word):
  return "Does {} not has {}?".format(questionable_name, word)

def create_question_type_3(questionable_name, word_1, word_2, operator):
  return "Does {} has {} {} {}?".format(questionable_name, word_1, operator, word_2)

# does john has tail?
def create_question_type_4(questionable_name, word):
   antonym = get_antonym_of_word(word)
   if antonym:
      return "Does {} has {}?".format(questionable_name, antonym)
   else:
     return None

# Conjunction
import requests, re, traceback
import pandas as pd

def mapping_for_conjunction(klass, rel):
  url = '{}?start=/c/en/{}&rel=/r/{}&limit=1000'.format(CONCEPT_NET_URL, klass, rel)
  obj = requests.get(url).json()
  dataum = {}
  df_klass = pd.DataFrame()
  for edge in obj['edges']:
    if edge['surfaceText']:
      dataum[edge['end']['label']] = re.sub(PATTERN, "", edge['surfaceText'])
  
  temp = list(dataum)
  result = {'Questions': [], 'Answers': []}
  for i in range(0, len(temp)):
    word_1 = temp[i]
    for j in range(i+1, len(temp)):
      try:
          word_2 = temp[j]
          sent_1 = dataum[word_1]
          sent_2 = dataum[word_2]
          premise, questionable_name = create_premise(klass, sent_1, sent_2)
          questions_type1 = []; questions_type2 = []; questions_type3 = []; questions_type4 = []
          # does john has tail?
          for w in [word_1, word_2]:
            questions_type1.append(create_question_type_1(questionable_name, w))
            questions_type2.append(create_question_type_2(questionable_name, w))
            questions_type4.append(create_question_type_4(questionable_name, w))
          # does johhn has tail or fur?
          # does johhn has tail and fur?
          for oprand in OPERATORS:
            questions_type3.append(create_question_type_3(questionable_name, word_1, word_2, oprand))
          questions_type4_final_list = list(filter(None, questions_type4))
          q1 = question_answer_pairs(questions_type1, YES)
          q2 = question_answer_pairs(questions_type2, NO)
          q3 = question_answer_pairs(questions_type3, YES)
          q4 = question_answer_pairs(questions_type4_final_list, NO)
          result['Rules'] = 'Conjunction'
          result['Context'] = premise
          result['Questions'] = q1['Questions'] + q2['Questions'] + q3['Questions'] + q4['Questions']
          result['Answers'] = q1['Answers'] + q2['Answers'] + q3['Answers'] + q4['Answers']
          df_klass = pd.concat([df_klass, pd.DataFrame(result)], ignore_index=True)
      except Exception as e:
        print(e)
        print(traceback.format_exc())
        return df_klass
  return df_klass

from uuid import uuid4
dataset_df = pd.DataFrame(columns = CSV_COLUMNS)
current_words = ["countries", "animals", "cities", "sports", "cultures", "dogs", "cats", "buildings", "colleges", "subjects", "lakes", "mountains", "dishes"]

for noun in current_words:
  for rel in CONJUNCTION_RELATIONS:
    try:
      dn = mapping_for_conjunction(noun, rel)
      dataset_df = pd.concat([dataset_df, pd.DataFrame(dn)], ignore_index=True)
    except Exception as e:
      print(e)
      print(traceback.format_exc())
      continue
# df['UUID'] = df.index.to_series().map(lambda x: uuid4())
# len(df)
# df.to_csv("Dataset5_AyushKalani.csv", sep=',', index=False)

"""**ADDITION**"""

import inflect
inflect = inflect.engine()

def is_word_plural(w):
  try:
    return not inflect.singular_noun(w) == False
  except Exception as e:
    return False

def create_addition_question_type_1(questionable_name, entity):
  url = '{}?start=/c/en/{}&rel=/r/RelatedTo'.format(CONCEPT_NET_URL, entity)
  obj = requests.get(url).json()
  questions = []

  for edge in obj['edges']:
    questions.append("Is {} a {} or {}".format(questionable_name, entity, edge['end']['label']))
    if (not is_word_plural(entity)) and (not is_word_plural(edge['end']['label'])):
      questions.append("Is {} a {} or not a {}".format(questionable_name, entity, edge['end']['label']))
  return questions

def create_addition_question_type_2(questionable_name, entity):
  return "Is {} not a {}?".format(questionable_name, entity)

# Addition
import requests, re, traceback
import pandas as pd

def mapping_for_addition(klass, relation):
  url = '{}?start=/c/en/{}&rel=/r/{}&limit=1000'.format(CONCEPT_NET_URL, klass, relation)
  obj = requests.get(url).json()
  dataum = {}
  df_klass = pd.DataFrame()
  for edge in obj['edges']:
    if edge['surfaceText']:
      dataum[edge['end']['label']] = re.sub(PATTERN, "", edge['surfaceText'])
  
  temp = list(dataum)
  result = {'Questions': [], 'Answers': []}
  for i in range(0, len(temp)):
    try:
        word_1 = temp[i]
        premise, questionable_name = create_premise(klass, dataum[word_1])
        questions_type1 = []; questions_type2 = []
        questions_type1 = create_addition_question_type_1(questionable_name, word_1)
        questions_type2.append(create_addition_question_type_2(questionable_name, word_1))
        q1 = question_answer_pairs(questions_type1, YES)
        q2 = question_answer_pairs(questions_type2, NO)
        result['Rules'] = 'Addition'
        result['Context'] = premise
        result['Questions'] = q1['Questions'] + q2['Questions']
        result['Answers'] = q1['Answers'] + q2['Answers']
        df_klass = pd.concat([df_klass,pd.DataFrame(result)],ignore_index=True)
    except Exception as e:
      print(e)
      print(traceback.format_exc())
      return df_klass
  return df_klass

from uuid import uuid4
df = pd.DataFrame(columns=CSV_COLUMNS)
current_words = ["countries", "animals", "cities", "sports", "cultures", "dogs", "cats", "buildings", "colleges", "subjects", "lakes", "mountains", "dishes", 'area','book','business','case','child','company','country','day','eye','fact','family','government','group','hand','home','job','life','lot','man','money','month','mother','Mr','night','number','part','people','place','point','problem','program','question','right','room','school','state','story','student','study','system','thing','time','water','way','week','woman','word','work','world','year']

for noun in current_words:
  try:
    dn = mapping_for_addition(noun, "IsA")
    df = pd.concat([df, pd.DataFrame(dn)], ignore_index=True)
  except Exception as e:
    print(e)
    print(traceback.format_exc())
    continue
df['UUID'] = df.index.to_series().map(lambda x: uuid4())
len(df)
df.to_csv("Dataset5_AyushKalani.csv", sep=',', index=False)

"""**COMPOSITION**"""

# If Javier play, will Javier have fun?
# If Javier not play, will Javier have fun?
def create_composition_question_type_1(entity, questionable_name, *words):
  questions = []
  for w in words:
    questions.append("If {} {}, will {} {}?".format(questionable_name, entity, questionable_name, w))
    questions.append("If {} not {}, will  {} {}?".format(questionable_name, entity, questionable_name, w))
  return questions

# If Javier play, will Javier have fun and/or learn? YES
def create_composition_question_type_2(entity, questional_name, operator, word_1, word_2):
  return "If {} {}, will {} {} {} {}?".format(questional_name, entity, questional_name, word_1, operator, word_2)

# If Javier have fun, will Javier not play? NO
def create_composition_question_type_3(entity, questionable_name, *words):
  questions = []
  for w in words:
     questions.append("If {} {}, will {} not {}?".format(questionable_name, entity, questionable_name, w))
  return questions

# P = False, Q= False, p ->q TRUE, ANS = yes
def create_composition_question_type_4(entity, questionable_name, *words):
  questions = []
  for w in words:
     questions.append("If {} not {}, will {} not {}?".format(questionable_name, entity, questionable_name, w))
  return questions

# P = TRue, Q AND R = False, ans = NO
def create_composition_question_type_5(entity, questionable_name, word_1, word_2):
  return "If {} {}, will {} not {} and {}?".format(questionable_name, entity, questionable_name, word_1, word_2)

# P = TRue, Q AND R = False, ans = NO
def create_composition_question_type_6(entity, questionable_name, word_1, word_2):
  return "If {} not {}, will {} {} and {}?".format(questionable_name, entity, questionable_name, word_1, word_2)

# Composition
import requests, re, traceback, names
import pandas as pd

# If you want to [[play]] then you should [[have fun]]. If you want to [[play]] then you should [[relax]]. 
def mapping_for_composition(klass, relation):
  obj = requests.get('{}?start=/c/en/{}&rel=/r/{}'.format(CONCEPT_NET_URL, klass, relation)).json()
  dataum = {}
  df_klass = pd.DataFrame()
  for edge in obj['edges']:
    if edge['surfaceText']:
      dataum[edge['end']['label']] = re.sub(PATTERN, "", edge['surfaceText'])
  temp = list(dataum)
  result = {'Questions': [], 'Answers': []}
  for i in range(0, len(temp)):
    word_1 = temp[i]
    for j in range(i+1, len(temp)):
      try:
          word_2 = temp[j]
          sent_1 = dataum[word_1]
          sent_2 = dataum[word_2]
          questionable_name = names.get_first_name()
          premise = sent_1 + ". " + sent_2 + ". "
          questions_type1 = []; questions_type2 = []; questions_type3 = []; questions_type4 = []; questions_type5 = []; questions_type6 = []
          questions_type1 = create_composition_question_type_1(klass, questionable_name, word_1, word_2)
          for operand in OPERATORS:
            questions_type2.append(create_composition_question_type_2(klass, questionable_name, operand, word_1, word_2))
          questions_type3 = create_composition_question_type_3(klass, questionable_name, word_1, word_2)
          questions_type4 = create_composition_question_type_4(klass, questionable_name, word_1, word_2)
          questions_type5.append(create_composition_question_type_5(klass, questionable_name, word_1, word_2))
          questions_type6.append(create_composition_question_type_6(klass, questionable_name, word_1, word_2))
          q1 = question_answer_pairs(questions_type1, YES)
          q2 = question_answer_pairs(questions_type2, YES)
          q3 = question_answer_pairs(questions_type3, NO)
          q4 = question_answer_pairs(questions_type4, YES)
          q5 = question_answer_pairs(questions_type5, NO)
          q6 = question_answer_pairs(questions_type6, NO)
          result['Rules'] = 'Composition'
          result['Context'] = premise
          result['Questions'] = q1['Questions'] + q2['Questions'] + q3['Questions'] + q4['Questions'] + q5['Questions'] + q6['Questions']
          result['Answers'] = q1['Answers'] + q2['Answers'] + q3['Answers'] + q4['Answers'] + q5['Answers'] + q6['Answers']
          df_klass = pd.concat([df_klass,pd.DataFrame(result)],ignore_index=True)
      except Exception as e:
        print(e)
        print(traceback.format_exc())
        return df_klass
  return df_klass

from uuid import uuid4
df = pd.DataFrame(columns=CSV_COLUMNS)

for noun in COMPOSITION_WORDS:
  try:
    for rel in COMPOSITION_RELATIONS:
      dn = mapping_for_composition(noun, rel)
      df = pd.concat([df, pd.DataFrame(dn)], ignore_index=True)
  except Exception as e:
    print(e)
    print(traceback.format_exc())
    continue
df['UUID'] = df.index.to_series().map(lambda x: uuid4())
df.to_csv("Dataset5_AyushKalani.csv", sep=',', index=False)

"""**De Morgan's Theorem (1)**

**P AND Q** = Miguel has a cellphone and he has a laptop computer can be written as Miguel has both a cellphone and a laptop compute. <br />
***negation, NOT (P AND Q) is (NOT P) OR (NOT Q)***<br />
Explaination - "Miguel does not have both a cellphone and a laptop computer", which means that he is missing at least one of the two items:
he may not have a cellphone, or he may not have a laptop, or he may have neither. Mathematically, if we use "or", there's no need to add the "or both" at the end, so we can shorten it to this: miguel does not have a cell phone or doels not have a laptop
 <br />
**SOLUTION** Miguel does not have a cellphone or he does not have a laptop computer.‚Äù

Reference - [DeMorgan1](https://math.stackexchange.com/questions/2890131/example-of-use-de-morgan-law-and-the-plain-english-behind-it)
[DeMorgan Explained](https://stackoverflow.com/questions/2168603/de-morgans-rules-explained)
[Examples](https://courses.lumenlearning.com/waymakermath4libarts/chapter/demorgans-laws/)
"""

def create_neg_premise1(questional_name, word_1, word_2):
  return "{} does not have both {} and does not have {}".format(questional_name, word_1, word_2)

def create_neg_premise2(questional_name, word_1, word_2):
  return "{} does not have either {} or {}".format(questional_name, word_1, word_2)

# does mike does not have a phone?
# does mike does not have a charger?
# ans = YES
def create_dm_question_type_1(entity, *words):
  questions = []
  for w in words:
    questions.append("Does {} does not have {}?".format(entity, w))
  return questions

# does mike does have a phone?
# does mike does have a charger?
# ans = NO
def create_dm_question_type_2(entity, *words):
  questions = []
  for w in words:
    questions.append("Does {} have {}?".format(entity, w))
  return questions

#YES
def create_dm_question_type_3(entity, word_1, word_2):
  return "Does {} have {} and not have {}?".format(entity, word_1, word_2)
#YES
def create_dm_question_type_4(entity, word_1, word_2):
  return "Does {} not have {} and have {}?".format(entity, word_1, word_2)  
#YES
def create_dm_question_type_5(entity, word_1, word_2):
  return "Does {} not have {} and not have {}?".format(entity, word_1, word_2)
#NO
def create_dm_question_type_6(entity, word_1, word_2):
  return "Does {} have {} and have {}?".format(entity, word_1, word_2)

# De Morgan's 1
import requests, re, traceback, names
import pandas as pd

#  Miguel has a [[cellphone]] and he has a [[laptop computer]]
# I pay taxes and I vote."
def mapping_for_demorgan_1(klass, relation):
  obj = requests.get('{}?start=/c/en/{}&rel=/r/{}'.format(CONCEPT_NET_URL, klass, relation)).json()
  dataum = {}
  df_klass = pd.DataFrame()
  for edge in obj['edges']:
    if edge['surfaceText']:
      dataum[edge['end']['label']] = re.sub(PATTERN, "", edge['surfaceText'])
  temp = list(dataum)
  result = {'Questions': [], 'Answers': []}
  for i in range(0, len(temp)):
    word_1 = temp[i]
    for j in range(i+1, len(temp)):
      try:
          word_2 = temp[j]
          sent_1 = dataum[word_1]
          sent_2 = dataum[word_2]
          questions_type1 = []; questions_type2 = []; questions_type3 = []; questions_type4 = []; questions_type5 = []; questions_type6 = []
          premises = [create_neg_premise1(klass, word_1, word_2), create_neg_premise2(klass, word_1, word_2)]
          for premise in premises:
            questions_type1.extend(create_dm_question_type_1(klass, word_1, word_2))
            questions_type2.extend(create_dm_question_type_2(klass, word_1, word_2))
            questions_type3.append(create_dm_question_type_3(klass, word_1, word_2))
            questions_type4.append(create_dm_question_type_4(klass, word_1, word_2))
            questions_type5.append(create_dm_question_type_5(klass, word_1, word_2))
            questions_type5.append(create_dm_question_type_6(klass, word_1, word_2))
            
            q1 = question_answer_pairs(questions_type1, YES)
            q2 = question_answer_pairs(questions_type2, NO)
            q3 = question_answer_pairs(questions_type3, YES)
            q4 = question_answer_pairs(questions_type4, YES)
            q5 = question_answer_pairs(questions_type5, YES)
            q6 = question_answer_pairs(questions_type6, NO)

            result['Rules'] = 'De Morgan Law 1'
            result['Context'] = premise
            result['Questions'] = q1['Questions'] + q2['Questions'] + q3['Questions'] + q4['Questions'] + q5['Questions'] + q6['Questions']
            result['Answers'] = q1['Answers'] + q2['Answers'] + q3['Answers'] + q4['Answers'] + q5['Answers'] + q6['Answers']
            df_klass = pd.concat([df_klass,pd.DataFrame(result)],ignore_index=True)
      except Exception as e:
        print(e)
        print(traceback.format_exc())
        return df_klass
  return df_klass

from uuid import uuid4
df = pd.DataFrame(columns=CSV_COLUMNS)
current_words = ["animals", "countries", "cities", "sports", "cultures", "dogs", "cats", "buildings", "colleges", "subjects", "lakes", "mountains", "dishes", 'area','book','business','case','child','company','country','day','eye','fact','family','government','group','hand','home','job','life','lot','man','money','month','mother','Mr','night','number','part','people','place','point','problem','program','question','right','room','school','state','story','student','study','system','thing','time','water','way','week','woman','word','work','world','year']

for noun in current_words:
  try:
    dn = mapping_for_demorgan_1(noun, "HasA")
    df = pd.concat([df, pd.DataFrame(dn)], ignore_index=True)
  except Exception as e:
    print(e)
    print(traceback.format_exc())
    continue
df['UUID'] = df.index.to_series().map(lambda x: uuid4())
len(df)
df.to_csv("Dataset5_AyushKalani.csv", sep=',', index=False)

"""**Driver Method To generate single CSV dataset**"""

from uuid import uuid4
dataset_df = pd.DataFrame(columns=CSV_COLUMNS)


# Conjunction
# might timeout run seperately and append
for noun in FREQUENT_WORDS:
  for rel in CONJUNCTION_RELATIONS:
    try:
      con_df = mapping_for_conjunction(noun, rel)
      dataset_df = pd.concat([dataset_df, pd.DataFrame(con_df)], ignore_index=True)
    except Exception as e:
      print(e)
      print(traceback.format_exc())
      continue

# Addition
for noun in FREQUENT_WORDS:
  for rel in ADDITION_RELATIONS:
    try:
      add_df = mapping_for_addition(noun, rel)
      dataset_df = pd.concat([dataset_df, pd.DataFrame(add_df)], ignore_index=True)
    except Exception as e:
      print(e)
      print(traceback.format_exc())
      continue

# Composition
for noun in COMPOSITION_WORDS:
  for rel in COMPOSITION_RELATIONS:
    try:
      comp_df = mapping_for_composition(noun, rel)
      dataset_df = pd.concat([dataset_df, pd.DataFrame(comp_df)], ignore_index=True)
    except Exception as e:
      print(e)
      print(traceback.format_exc())
      continue

 # De Morgan 1
for noun in FREQUENT_WORDS:
  for rel in DEMORGAN_1_RELATIONS:
    try:
      dm_df = mapping_for_demorgan_1(noun, rel)
      dataset_df = pd.concat([dataset_df, pd.DataFrame(dm_df)], ignore_index=True)
    except Exception as e:
      print(e)
      print(traceback.format_exc())
      continue   

dataset_df['UUID'] = dataset_df.index.to_series().map(lambda x: uuid4())
dataset_df.to_csv("Dataset5_AyushKalani.csv", sep=',', index=False)
len(dataset_df)